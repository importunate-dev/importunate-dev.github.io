---
layout: post
title: ' 효율성에 매몰되지 않기 '
subtitle: ' 2024년 2월 2일 금요일 '
catalog: true
category: log
subcategory: weekly
tags:
  - log
  - february
  - 2024
  - python
  - google api
  - spreadsheet
  - cron

---

# Today I Learned

## 날짜

2024년 2월 2일 금요일

## 내용

### 삼지선다

 나름 기가 막힌 아이디어가 떠올라서, 어제의 Task를 처리했다. 내가 달성해야 할 구현 목표는 다음과 같다.

- 구글 스프레드시트에 있는 데이터는 기존 행에 새로운 값을 덮어써준다.
- 구글 스프레드시트에 없지만 2024년 2월 이후 가입했거나, 기존에 가입했으나 새로 AI 서비스를 이용하게 된 고객의 데이터는 새로운 행에 추가해준다.
- 서비스에서 탈퇴해 데이터가 없어졌을 떈 스프레드시트에서도 삭제한다.

  추가된 데이터를 한번 정제해서 쓰면 되니 굳이 API가 완벽하게 정리된 데이터를 만들 필요는 없다고 하셨지만 뭔가 놓치고 있다는 느낌이 자꾸 들어 기존의 걸림돌을 되짚어봤다.

1.  8개의 데이터 중 7개는 샵 서버에서, 1개는 리뷰 서버에서 처리해야 한다. 바꾸는 것과 생성하는 요청은 종류가 다르다. 이 모든걸 고려해야한다.
    1. 우선 동의를 구하고 리뷰 서버에서 처리할 데이터를 한쪽으로 미뤄뒀다. 샵 서버에선 1~7열을 한번에 요청할 수 있게 되었다. 번거로움이 덜 해졌다.
2. 업데이트할 범위를 행과 열의 값으로 지정해야 하므로 고유값인 shop id로 정렬해야 한다.
    1. 이 부분을 꼭 해결하고 싶었다. 내가 잠시 간과하고 있던 사실은, 스프레드 시트에 없지만 위에서 언급한 특정 조건을 만족하는 데이터는 새로 생성해야 한다. 바꿔 말하면, 조건을 만족하지 않는 샵은 스프레드시트에 존재할 필요가 없다는 의미다. 나는 어느새 모든 shop을 스프레드시트에 추가하는 것으로 생각하고 있었고, 새로 추가되어야 할 데이터를 어떻게 파악할 것인지를 놓치고 있었다. 이 고민 때문에 결국 “스프레드 시트에 있는 데이터들에서 shop_id 가져와야만 한다”고 생각하게 됐다.
        
         스프레드시트에 데이터를 가져올 때, 그 데이터의 위치정보를 같이 가져오면 어떨까? 물론 새로 추가하는 데는 위치정보가 필요 없다. 하지만 시트에 몇번 행의 shop_id가 무엇인지를 알고 있다면, 업데이트할 때 “이 shop_id는 어디 행에 있으니 거길 업데이트 해”라고 명령할 수 있다. 그렇다면 shop_id를 index로 사용하기 위해 고정할 필요도 없다. 
        
         로직을 정리하면 다음과 같다.
        
        1. 현재 스프레드시트에 존재하는 shop_id와 그 위치(행)을 가져온다.
        2. 샵에 대한 정보 중, 스프레드시트에 이미 있다면 그 위치는 업데이트한다.
        3. 샵에 대한 정보 중, 시트에 없지만 추가해야 한다면 그 데이터를 새로운 행으로 추가한다.
        4. 샵에 대한 정보 중, 시트에 있지만 데이터베이스에 없다면 그 행은 삭제한다.
        
        한 가지 걸림돌은 행이 삭제될 경우, 그 아래의 데이터들의 행값은 1씩 감소하는 문제였다. 스프레드시트 API에서 `batchUpdate` 다양한 요청을 한꺼번에 처리하는 메서드이다. 단순히 업데이트만 해주는게 아니라 새로운 행 추가, 기존 행 삭제, 기존 행 덮어쓰기를 위치 변화 없이 적용한 후 한꺼번에 정리해준다. 따라서 걸림돌을 해결할 수 있었다.
        

근데 스크립트는 로컬에선 잘 되면서 왜 테스트서버에서 하면 한번에 작동 되는 일이 없는걸까? 하…

## 회고

효율적으로, 간편하게만 구현하려고 생각하니 할 수 있는 것을 놓칠 뻔 했다.
