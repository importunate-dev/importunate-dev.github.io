---
layout: post
title: "6장 메모리와 캐시 메모리"
subtitle: " 혼자서 공부하는 컴퓨터 구조와 운영체제 "
catalog: true
category: study
subcategory: cs_alone
tags:
  - study
  - cs_alone
  - 휘발성 저장 장치
  - 비휘발성 저장 장치
  - DRAM
  - SRAM
  - SDRAM
  - DDR SDRAM
  - 물리 주소
  - 논리 주소
  - MMU
  - 베이스 레지스터
  - 한계 레지스터
  - 저장 장치 계층 구조
  - 캐시 메모리
  - 캐시 적중률
  - 참조 지역성의 원리
---

# 06-1 RAM의 특징과 종류

## RAM의 특징

실행할 프로그램의 명령어와 데이터가 저장

**휘발성 저장 장치(volatile memory)**

- 전원을 끄면 저장된 명령어와 데이터가 사라짐
- CPU가 실행할 대상을 저장

**비휘발성 저장 장치(non-volatile memory)**

- 전원을 꺼도 저장된 내용을 유지.
- 하드 디스크, USB 같은 보조기억장치
- CPU는 보조기억장치에 접근하지 못함

## RAM의 용량과 성능

- RAM 용량이 크면 실행할 프로그램을 많이 저장할 수 있음.
- 따라서 동시에 여러 프로그램을 빠르게 처리할 수 있음

## RAM의 종류

### DRAM

- Dynamic RAM
- 시간이 지나면 저장된 데이터가 점차 사라짐
- 따라서 일정 주기로 데이터를 재활성화(다시 저장)해야 함
- 소비 전력이 낮고, 저렴하고, 집적도가 높아 대용량으로 설계하기 용이함

### SRAM

- Static RAM
- 시간이 지나도 데이터가 사라지지 않음
- 소비 전력이 높고, 비싸고, 집적도가 낮음
- 캐시 메모리등에 사용
    - 정확히는 CPU 내부의 캐시 메모리에서 사용한다.
    - SRAM은 데이터 재활성화가 필요없어 액세스 속도가 매우 빠르다.
    - CPU의 캐시 용량은 메인 메모리(16GB, 32GB, …)에 비해선 여전히 작음(수십 MB)

### SDRAM

- Synchronous Dynamic RAM
    - 또는 SDR SDRAM(Single Data Rate SDRAM)
- 클럭 신호와 동기화된, 발전도니 형태의 DRAM
- 클럭 타이밍에 맞춰 CPU와 정보를 주고 받을 수 있음
- 클럭 타이밍을 맞추는게 중요한 이유
    - 정확히는 데이터 전송의 타이밍을 CPU의 동작 속도(시스템 쿨럭)과 맞춘다는 의미임
    - DRAM등 에서는 데이터를 언제 줄지 몰라 유휴시간이 존재하는 등 비효율성이 발생했음
    1. SDRAM은 클럭에 맞춰 오기떄문에 정확한 타이밍을 위해 준비할 수 있음
    2. 클럭속도?
        1. 클럭속도는 시스템 전체가 공유하는 기본 타이밍 신호임
        2. 여러 종류가 있으나 CPU와 RAM은 주로 시스템 클럭(System Clock) 기반의 신호들을 공유
        3. 시스템 클럭은 메인보드에 있는 클럭 제너레이터(Clock Generator)에서 생성됨
        4. 이게 CPU, RAM, 칩셋에게 공유
        5. 오버클럭등을 이용해 클럭신호는 바뀔수 있음
        6. CPU와 SDRAM은 클럭 제너레이터가 만드는 클럭 신호를 기반으로 같은 타이밍에 통신함

### DDR SDRAM

- Double Date Rate SDRAM
- **대역폭(data rate)**을 넓혀 속도를 빠르게 만든 SDRAM
    - 대역폭: 데이터를 주고 받는 길의 너비
- DDR2(2배), DDR3(4배), …

### 질문

1. SDRAM이 클럭 을 따지는게 뭔상관이지 어차피 CPU랑 주고받는데?
    1. 정확히는 데이터 전송의 타이밍을 CPU의 동작 속도(시스템 쿨럭)과 맞춘다.
    2. 기존에는 데이터를 언제 줄지 몰라 유휴시간이 존재하는 등 비효율성 발생했음
    3. SDRAM은 클럭에 맞춰 오기떄문에 정확한 타이밍을 위해 준비할 수 있음
    4. 클럭속도는 시스템전체가 공유하나? SDRAM이 어떻게알지? 이건 안변하나?
        1. 클럭속도는 시스템 전체가 공유하는 기본 타이밍 신호
        2. 여러 종류가 있으나 CPU와 RAM은 주로 시스템 클럭(System Clock) 기반의 신호들을 공유
        3. 시스템 클럭은 메인보드에 있는 클럭 제너레이터(Clock Generator)에서 생성됨. 이게 CPU, RAM, 칩셋에게 공유
        4. 오버클럭등을 이용해 클럭신호는 바뀔수 있음
2. 캐시도 이제 용량이 커서 몇기가씩 되는데 그래도 SRAM을 쓰나?
    1. 정확히는 CPU 내부의 캐시 메모리에서 사용한다.
    2. SRAM은 데이터 재활성화가 필요없어 액세스 속도가 매우 빠르다.
        1. CPU의 캐시 용량은 메인 메모리(16GB, 32GB, …)에 비해선 여전히 작음(수십 MB)

# 06-2 메모리의 주소 공간

**물리 주소**: 메모리 하드웨어가 사용하는 주소

**논리 주소**: CPU와 실행중인 프로그램이 사용하는 주소

## 물리 주소와 논리 주소

메모리에 저장된 정보는 시시각각 변한다.

메모리에는 새롭게 실행되는 프로그램이 시시때때로 적재되고, 삭제되기 때문이다.

CPU와 실행 중인 프로그램은 메모리의 모든 정보를 알고 있을 필요는 없다.

**물리 주소(physical address)**: 정보가 실제로 저장된 하드웨어상의 주소

**논리 주소(logical address)**: 실행 중인 프로그램 각각에게 부여된 0번지부터 시작되는 주소

프로그램은 각자 자신의 논리 주소를 가지고 있다.

따라서 프로그램마다 같은 논리 주소가 얼마든지 있을 수 있다.

**메모리 관리 장치(Memory Management Unit)**

- 논리 주소와 물리 주소 간의 변환
- CPU와 주소 버스 사이에 위치
- 프로그램과 CPU과 논리 주소로 말하더라도, 메모리와 CPU는 물리 주소로 이야기해야함

**베이스 레지스터**

- 프로그램의 가장 작은 물리 주소
- 프로그램의 첫 물리 주소를 저장
- 논리 주소는 프로그램의 시작점(베이스 레지스터)으로부터 떨어진 거리를 의미
- ex) 베이스 레지스터가 15000, CPU가 발생시킨 논리 주소가 100번지라면 물리 주소 15100번지로 변환

## 메모리 보호 기법

**한계 레지스터(limit register)**

- 논리 주소의 최대 크기를 저장
- 베이스 레지스터 값 ≤ 프로그램의 물리 주소 범위 < (베이스 레지스터 값 + 한계 레지스터 값)
- A 프로그램이 1000~1999번지, B 프로그램이 2000~2999번지에 저장되어 있다고 가정
    - A 프로그램에서 논리주소 1300번지에 데이터를 저장하거나 삭제하라고 명령한다면?
    - A 프로그램이 B 프로그램에 영향을 끼치게 되므로 위험함
- CPU가 한계 레지스터보다 높은 논리 주소에 접근하려고 하면 인터럽트를 발생시킴

# 06-3 캐시 메모리

## 저장 장치 계층 구조

CPU와 가까운 저장 장치는 빠르고, 멀리 있는 저장 장치는 느리다.

속도가 빠른 저장 장치는 저장 용량이 작고, 가격이 비싸다.

**저장 장치 계층 구조(memory hierarchy)**

- 컴퓨터가 사용하는 저장 장치들은 ‘CPU에 얼마나 가까운가’를 기준으로 나타낸 계층
- 레지스터 → 메모리 → 보조기억장치로 갈수록 느리고, 용량이 크며, 저렴하다.

## 캐시 메모리

CPU의 연산 속도가 아무리 빨라도 메모리에 접근하는 속도가 그에 따라가지 못하면 CPU의 속도는 의미가 없다.

**캐시 메모리(cache memory)**

- CPU와 메모리 사이에 위치하고, 레지스터보다 용량이 크고 메모리보다 빠른 SRAM 기반의 저장 장치
- CPU의 연산 속도와 메모리 접근 속도의 차이를 줄이기 위한 저장 장치
- 저장 장치 계층 구조에서 레지스터와 메모리 사이에 위치함
- 코어와 가까운 순서로 L1 캐시, L2 캐시, L3 캐시라고 함(level)
    - 일반적으로 L1 캐시와 L2 캐시는 코어 내부에, L3 캐시는 코어 외부에 위치
    - L1 캐시, L2 캐시는 코어마다 고유한 캐시 메모리로 할당
    - L3 캐시는 여러 코어가 공유하는 형태로 사용
- 코어는 레지스터 → L1 → L2 → L3 → 메모리 순서로 데이터를 찾음
- 앞선 4개를 거치고 메모리에 가더라도, 바로 메모리로 가는것 보다 빠름
- **분리형 캐시(split cache)**: L1 캐시를 분리
    - L1I 캐시: 명령어(Instruction)만 저장
    - L1D 캐시: 데이터(Data)만 저장

## 참조 지역성 원리

**캐시 히트(cache hit)**: 자주 사용될 것으로 예측한 데이터가 실제로 들어맞아 캐시 메모리 내 데이터가 CPU에서 활용될 경우

**캐시 미스(cache miss)**: 예측이 틀려 메모리에서 필요한 데이터를 직접 가져와야 하는 경우

- 자주 발생하면 캐시 메모리의 이점을 활용할 수 없어 성능 저하

**캐시 적중률(cache hit ratio)** = 캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)

**참조 지역성의 원리(locality of reference, principle of locality)**

- 캐시 메모리가 메모리로부터 가져올 데이터를 결정하는 원칙
    - CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향이 있다.
- CPU는 접근한 메모리 공간 근처를 접근하려는 경향이 있다.

### 최근에 접근했던 메모리 공간에 다시 접근하려는 경향

- **시간 지역성(temporal locality)**
- 프로그래밍 언어에서 변수에 값을 저장하면 다시 변수에 접근하여 값을 사용할 수 있다.
- 즉, CPU는 변수가 저장된 메모리 공간을 언제든 다시 참조할 수 있다.
- 변수를 코어로 가져올 때 캐시 메모리를 거치고, 이때 저장된다.
- **LRU(Least Recently Used)**: 오랫동안 안 쓰인 데이터는 삭제

### 접근한 메모리 공간 근처를 접근하려는 경향

- **공간 지역성(spatial locality)**
- CPU가 실행하려는 프로그램은 보통 관련 데이터들끼리 한데 모여 있음
- 하나의 프로그램 내에서도 관련 있는 데이터들은 모여서 저장됨
- 캐시 라인(Cache line) 단위로 주변 데이터까지 가져와서 저장